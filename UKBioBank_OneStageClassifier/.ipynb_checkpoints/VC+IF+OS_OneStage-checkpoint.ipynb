{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VC + IF + OS, one-stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from numpy import mean\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "#from autoimpute.imputations import MultipleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix, precision_recall_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Updated_UKBioBank.xlsx\")\n",
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific to UK BioBank dataset\n",
    "class PreProcessing:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def cleaning(self):\n",
    "        new_df = self.df.copy()\n",
    "        new_df = new_df.iloc[:, new_df.columns != 'QTrest']\n",
    "        new_df = new_df[~((new_df['AF']==1) & (new_df['Arr']==1))] # remove overlaps\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "        new_df = pd.DataFrame(imp.fit_transform(new_df), columns=new_df.columns)\n",
    "        new_df.loc[(new_df['Arr'] == 0) & (new_df['AF'] == 0), 'Category'] = 0\n",
    "        new_df.loc[(new_df['Arr'] == 0) & (new_df['AF'] == 1), 'Category'] = 1\n",
    "        new_df.loc[(new_df['Arr'] == 1) & (new_df['AF'] == 0), 'Category'] = 2\n",
    "        self.df = new_df\n",
    "        return self.df\n",
    "    \n",
    "    def getTrainTestSet(self):\n",
    "        new_df = self.cleaning()\n",
    "        choosing_samples_AF = new_df[new_df['AF'] == 1]\n",
    "        choosing_samples_Arr =  new_df[new_df['Arr'] == 1]\n",
    "        healthy_samples = new_df[new_df['Category'] == 0]\n",
    "        \n",
    "        AF_x = choosing_samples_AF.loc[:,choosing_samples_AF.columns != 'Category']\n",
    "        AF_y = choosing_samples_AF['Category']\n",
    "        \n",
    "        Arr_x = choosing_samples_Arr.loc[:,choosing_samples_Arr.columns != 'Category']\n",
    "        Arr_y = choosing_samples_Arr['Category']\n",
    "        \n",
    "        healthy_x = healthy_samples.loc[:,healthy_samples.columns != 'Category']\n",
    "        healthy_y = healthy_samples['Category']\n",
    "        \n",
    "        \n",
    "        AF_X_train, AF_X_test, AF_y_train, AF_y_test = train_test_split(AF_x, AF_y, test_size=0.35)\n",
    "        Arr_X_train, Arr_X_test, Arr_y_train, Arr_y_test = train_test_split(Arr_x, Arr_y, test_size=0.35)\n",
    "        healthy_X_train, healthy_X_test, healthy_y_train, healthy_y_test = train_test_split(healthy_x, healthy_y, test_size=0.35)\n",
    "        \n",
    "        X_test_df = pd.concat([AF_X_test,Arr_X_test,healthy_X_test])\n",
    "        y_test_df = pd.concat([AF_y_test,Arr_y_test,healthy_y_test])\n",
    "        X_train_df = pd.concat([AF_X_train,Arr_X_train,healthy_X_train])\n",
    "        y_train_df = pd.concat([AF_y_train,Arr_y_train,healthy_y_train])\n",
    "        X_train_df['Category'] = y_train_df\n",
    "        X_test_df['Category'] = y_test_df\n",
    "        self.df = X_train_df\n",
    "        return self.df, X_test_df\n",
    "    \n",
    "    # remving outliers using Isolation Forest\n",
    "    def OutlierRemoval(self):\n",
    "        new_df, X_test_df = self.getTrainTestSet()\n",
    "        new_df_healthy = new_df[new_df['Category'] == 0]\n",
    "        new_df_disease = new_df[(new_df['Category'] == 1)|(new_df['Category'] == 2)]\n",
    "        data = new_df_healthy.drop(columns=['AF', 'Arr']).values\n",
    "        X , y = data[:, :-1], data[:, -1]\n",
    "        iso = IsolationForest(random_state=4, contamination=0.5)\n",
    "        yhat = iso.fit_predict(X)\n",
    "        # select all rows that are not outliers\n",
    "        mask = yhat != -1\n",
    "        afterX, aftery = X[mask, :], y[mask]\n",
    "        no_outliers = pd.DataFrame(afterX, columns=new_df_healthy.drop(columns=['AF', 'Arr', 'Category']).columns)\n",
    "        no_outliers['Category'] = aftery\n",
    "        df1 = new_df_healthy.copy()\n",
    "        df1 = new_df_healthy.set_index('eid')\n",
    "        df2 = no_outliers.copy()\n",
    "        df2 = no_outliers.set_index('eid')\n",
    "        final_healthy_df = pd.merge(df1, df2, how='inner')\n",
    "        final_healthy_df['eid'] = df2.index\n",
    "        final_df = pd.concat([final_healthy_df, new_df_disease])\n",
    "        self.df = final_df\n",
    "        return self.df, X_test_df\n",
    "    \n",
    "    def DataAugmentation(self):\n",
    "        new_df, X_test_df = self.OutlierRemoval()\n",
    "        healthy_df = new_df[new_df['Category'] == 0]\n",
    "        AF_data = new_df.drop(columns=['Arr'], axis=1) # data with only the AF label\n",
    "        Arr_data = new_df.drop(columns=['AF'], axis=1) # data with only the Arr label\n",
    "        \n",
    "        arr_x = Arr_data.loc[:,Arr_data.columns != 'Arr']\n",
    "        arr_y = Arr_data['Arr']\n",
    "\n",
    "        oversample_arr = RandomOverSampler(random_state=42, sampling_strategy=0.8)\n",
    "        arr_x, arr_y = oversample_arr.fit_resample(arr_x, arr_y)\n",
    "        \n",
    "        af_x = AF_data.loc[:,AF_data.columns != 'AF']\n",
    "        af_y = AF_data['AF']\n",
    "\n",
    "        oversample_af = RandomOverSampler(random_state=42, sampling_strategy=0.8)\n",
    "        af_x, af_y = oversample_arr.fit_resample(af_x, af_y)\n",
    "    \n",
    "        arr_x['Arr'] = arr_y\n",
    "        af_x['AF'] = af_y\n",
    "\n",
    "        AF_only = af_x[af_x['AF'] == 1] # data with only positive labels of AF\n",
    "        Arr_only = arr_x[arr_x['Arr'] ==1] # data with only positive labels of Arr\n",
    "        with_oversample_df = pd.concat([AF_only, Arr_only,healthy_df])\n",
    "        \n",
    "        with_oversample_df.loc[(with_oversample_df['Arr'].isnull()) & (with_oversample_df['AF'] == 1), 'Arr'] = 0\n",
    "        with_oversample_df.loc[(with_oversample_df['AF'].isnull()) & (with_oversample_df['Arr'] == 1), 'AF'] = 0\n",
    "        \n",
    "        with_oversample_df.loc[(with_oversample_df['Arr'] == 0) & (with_oversample_df['AF'] == 0), 'Category'] = 0\n",
    "        with_oversample_df.loc[(with_oversample_df['Arr'] == 0) & (with_oversample_df['AF'] == 1), 'Category'] = 1\n",
    "        with_oversample_df.loc[(with_oversample_df['Arr'] == 1) & (with_oversample_df['AF'] == 0), 'Category'] = 2\n",
    "        self.df = with_oversample_df\n",
    "        return self.df, X_test_df\n",
    "    def finalCleanedDf(self):\n",
    "        new_df, X_test_df = self.DataAugmentation()\n",
    "        new_df.loc[(new_df['Arr'] == 1) & (new_df['Category'] == 2), 'AF'] = 0\n",
    "        new_df.loc[(new_df['AF'] == 1) & (new_df['Category'] == 1), 'Arr'] = 0\n",
    "        self.df = new_df\n",
    "        return self.df, X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = PreProcessing(df)\n",
    "train_df, test_df= instance.finalCleanedDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Arr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['eid', 'AF', 'Arr', 'Category'])\n",
    "y_train = train_df['Category']\n",
    "\n",
    "\n",
    "X_test = test_df.drop(columns=['eid', 'AF', 'Arr', 'Category'])\n",
    "y_test = test_df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "\n",
    "# model1 = xgb.XGBClassifier(objective='multi:softprob', subsample=0.75,  \n",
    "#                           n_estimators=100, colsample_bytree = 0.99, learning_rate = 1,\n",
    "#                 max_depth = 10,  gamma=5, alpha = 1, seed=123, use_label_encoder=False, eval_metric='error')\n",
    "\n",
    "# estimators.append(('XGBoost', model1))\n",
    "# estimators.append(('bayes', GaussianNB()))\n",
    "# estimators.append(('GradientDescent' , SGDClassifier(loss=\"modified_huber\", penalty=\"elasticnet\", max_iter=500)))\n",
    "# ensemble = VotingClassifier(estimators, voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = xgb.XGBClassifier(objective='multi:softmax', subsample=0.75,  \n",
    "                          n_estimators=100, colsample_bytree = 0.7, learning_rate = 0.99,\n",
    "                max_depth = 20, gamma=5, alpha = 1, seed=123,use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['merror', 'mlogloss']\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "ensemble.fit(X_train, y_train, eval_metric=metrics, eval_set=eval_set, verbose=False)\n",
    "y_pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating  a confusion matrix,which compares the y_test and y_pred\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['Healthy','AF','Arr'], \n",
    "                     columns = ['Healthy','AF','Arr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "print('f1_score: %.3f' % f1_score)\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print('Precision: %.3f' % precision)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print('Recall: %.3f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
