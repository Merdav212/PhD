{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG + SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from numpy import mean\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "#from autoimpute.imputations import MultipleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix, precision_recall_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Updated_UKBioBank.xlsx\")\n",
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific to UK BioBank dataset\n",
    "class PreProcessing:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def cleaning(self):\n",
    "        new_df = self.df.copy()\n",
    "        new_df = new_df.iloc[:, new_df.columns != 'QTrest']\n",
    "        new_df = new_df[~((new_df['AF']==1) & (new_df['Arr']==1))] # remove overlaps\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "        new_df = pd.DataFrame(imp.fit_transform(new_df), columns=new_df.columns)\n",
    "        new_df.loc[(new_df['Arr'] == 1) | (new_df['AF'] == 1), 'Disease'] = 1\n",
    "        new_df.loc[(new_df['Arr'] == 0) & (new_df['AF'] == 0), 'Disease'] = 0\n",
    "        self.df = new_df\n",
    "        return self.df\n",
    "    \n",
    "    def getTrainTestSet(self):\n",
    "        new_df = self.cleaning()\n",
    "        choosing_samples_AF = new_df[new_df['AF'] == 1]\n",
    "        choosing_samples_Arr =  new_df[new_df['Arr'] == 1]\n",
    "        healthy_samples = new_df[new_df['Disease'] == 0]\n",
    "        \n",
    "        AF_x = choosing_samples_AF.loc[:,choosing_samples_AF.columns != 'Disease']\n",
    "        AF_y = choosing_samples_AF['Disease']\n",
    "        \n",
    "        Arr_x = choosing_samples_Arr.loc[:,choosing_samples_Arr.columns != 'Disease']\n",
    "        Arr_y = choosing_samples_Arr['Disease']\n",
    "        \n",
    "        healthy_x = healthy_samples.loc[:,healthy_samples.columns != 'Disease']\n",
    "        healthy_y = healthy_samples['Disease']\n",
    "        \n",
    "        \n",
    "        AF_X_train, AF_X_test, AF_y_train, AF_y_test = train_test_split(AF_x, AF_y, test_size=0.1)\n",
    "        Arr_X_train, Arr_X_test, Arr_y_train, Arr_y_test = train_test_split(Arr_x, Arr_y, test_size=0.1)\n",
    "        healthy_X_train, healthy_X_test, healthy_y_train, healthy_y_test = train_test_split(healthy_x, healthy_y, test_size=0.01)\n",
    "        \n",
    "        X_test_df = pd.concat([AF_X_test,Arr_X_test,healthy_X_test])\n",
    "        y_test_df = pd.concat([AF_y_test,Arr_y_test,healthy_y_test])\n",
    "        X_train_df = pd.concat([AF_X_train,Arr_X_train,healthy_X_train])\n",
    "        y_train_df = pd.concat([AF_y_train,Arr_y_train,healthy_y_train])\n",
    "        X_train_df['Disease'] = y_train_df\n",
    "        X_test_df['Disease'] = y_test_df\n",
    "        self.df = X_train_df\n",
    "        return self.df, X_test_df\n",
    "    \n",
    "    # remving outliers using Isolation Forest\n",
    "    def OutlierRemoval(self):\n",
    "        new_df, X_test_df = self.getTrainTestSet()\n",
    "        new_df_healthy = new_df[new_df['Disease'] == 0]\n",
    "        new_df_disease = new_df[new_df['Disease'] == 1]\n",
    "        for_outlier_x = new_df_healthy.loc[:, ~new_df_healthy.columns.isin(['eid','AF', 'Arr', 'Disease'])]\n",
    "        for_outlier_y = new_df_healthy['Disease']\n",
    "        clf = LocalOutlierFactor(n_neighbors=2)\n",
    "        for_outlier_y_pred = clf.fit_predict(for_outlier_x)\n",
    "        for_outlier_x['outlier_score'] = for_outlier_y_pred\n",
    "        for_outlier_x['Disease'] = for_outlier_y\n",
    "        for_outlier_x['eid'] = new_df_healthy['eid']\n",
    "        for_outlier_x['Arr'] = new_df_healthy['Arr']\n",
    "        for_outlier_x['AF'] = new_df_healthy['AF']\n",
    "        without_outliers = for_outlier_x[for_outlier_x['outlier_score'] == 1]\n",
    "        without_outliers = without_outliers.loc[:,without_outliers.columns != 'outlier_score']\n",
    "        df1 = new_df_healthy.copy()\n",
    "        df1 = new_df_healthy.set_index('eid')\n",
    "        df2 = without_outliers.copy()\n",
    "        df2 = without_outliers.set_index('eid')\n",
    "        final_healthy_df = pd.merge(df1, df2, how='inner')\n",
    "        final_healthy_df['eid'] = df2.index\n",
    "        final_df = pd.concat([final_healthy_df, new_df_disease])\n",
    "        self.df = final_df\n",
    "        return self.df, X_test_df\n",
    "    \n",
    "    def DataAugmentation(self):\n",
    "        new_df, X_test_df = self.getTrainTestSet()\n",
    "        healthy_df = new_df[new_df['Disease'] == 0]\n",
    "        AF_data = new_df.drop(columns=['Arr'], axis=1) # data with only the AF label\n",
    "        Arr_data = new_df.drop(columns=['AF'], axis=1) # data with only the Arr label\n",
    "        arr_smote_x = Arr_data.loc[:,Arr_data.columns != 'Arr']\n",
    "        arr_smote_y = Arr_data['Arr']\n",
    "\n",
    "        oversample_arr = SMOTE(sampling_strategy=0.5)\n",
    "        arr_smote_x, arr_smote_y = oversample_arr.fit_resample(arr_smote_x, arr_smote_y)\n",
    "        af_smote_x = AF_data.loc[:,AF_data.columns != 'AF']\n",
    "        af_smote_y = AF_data['AF']\n",
    "\n",
    "        oversample_af = SMOTE(sampling_strategy=0.5)\n",
    "        af_smote_x, af_smote_y = oversample_af.fit_resample(af_smote_x, af_smote_y)\n",
    "        arr_smote_x['Arr'] = arr_smote_y\n",
    "        af_smote_x['AF'] = af_smote_y\n",
    "        AF_only = af_smote_x[af_smote_x['AF'] == 1] # data with only positive labels of AF\n",
    "        Arr_only = arr_smote_x[arr_smote_x['Arr'] ==1] # data with only positive labels of Arr\n",
    "        with_smote_df = pd.concat([Arr_only,AF_only,healthy_df])\n",
    "        \n",
    "        with_smote_df.loc[(with_smote_df['Arr'] == 1) | (with_smote_df['AF'] == 1), 'Disease'] = 1\n",
    "        with_smote_df.loc[(with_smote_df['Arr'] == 0) & (with_smote_df['AF'] == 0), 'Disease'] = 0\n",
    "        self.df = with_smote_df\n",
    "        return self.df, X_test_df\n",
    "    def finalCleanedDf(self):\n",
    "        new_df, X_test_df = self.DataAugmentation()\n",
    "        new_df.loc[(new_df['Arr'] == 1) & (new_df['Disease'] == 1), 'AF'] = 0\n",
    "        new_df.loc[(new_df['AF'] == 1) & (new_df['Disease'] == 1), 'Arr'] = 0\n",
    "        self.df = new_df\n",
    "        return self.df, X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = PreProcessing(df)\n",
    "train_df, test_df= instance.finalCleanedDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    52358\n",
       "0.0    51530\n",
       "Name: Disease, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    521\n",
       "1.0    186\n",
       "Name: Disease, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    690\n",
       "1.0     17\n",
       "Name: Arr, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Arr'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['eid', 'AF', 'Arr', 'Disease'])\n",
    "y_train = train_df['Disease']\n",
    "\n",
    "\n",
    "X_test = test_df.drop(columns=['eid', 'AF', 'Arr', 'Disease'])\n",
    "y_test = test_df['Disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "\n",
    "model1 = xgb.XGBClassifier(objective='binary:logistic', subsample=0.75,  \n",
    "                          n_estimators=100, colsample_bytree = 0.99, learning_rate = 1,\n",
    "                max_depth = 10,  gamma=5, alpha = 1, seed=123, use_label_encoder=False, eval_metric='error')\n",
    "\n",
    "estimators.append(('XGBoost', model1))\n",
    "# estimators.append(('bayes', GaussianNB()))\n",
    "# estimators.append(('GradientDescent' , SGDClassifier(loss=\"modified_huber\", penalty=\"elasticnet\", max_iter=500)))\n",
    "ensemble = VotingClassifier(estimators, voting = 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.fit(X_train, y_train)\n",
    "y_pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    52358\n",
       "0.0    51530\n",
       "Name: Disease, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 690, 1.0: 17})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    521\n",
       "1.0    186\n",
       "Name: Disease, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.059\n",
      "Precision: 0.353\n",
      "Recall: 0.032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate score\n",
    "score = f1_score(y_test, y_pred)\n",
    "print('F1 Score: %.3f' % score)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %.3f' % precision)\n",
    "\n",
    "\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %.3f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x139e71039d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(ensemble, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.98      0.84       521\n",
      "         1.0       0.35      0.03      0.06       186\n",
      "\n",
      "    accuracy                           0.73       707\n",
      "   macro avg       0.55      0.51      0.45       707\n",
      "weighted avg       0.64      0.73      0.64       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "               | Positive Prediction | Negative Prediction\n",
    "Positive Class | True Positive (TP)  | False Negative (FN)\n",
    "Negative Class | False Positive (FP) | True Negative (TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52358, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['Disease'] ==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecondStageProcessing:\n",
    "    def __init__(self, traindf, testdf):\n",
    "        self.traindf = traindf\n",
    "        self.testdf = testdf\n",
    "        \n",
    "    def prcoessing(self):\n",
    "        new_df = self.traindf.copy()\n",
    "        test_df = self.testdf.copy()\n",
    "        X_train_2ndStage = new_df.copy()\n",
    "        X_train_2ndStage = X_train_2ndStage[X_train_2ndStage['Disease']==1]\n",
    "        X_train_2ndStage['label'] = 0\n",
    "        X_train_2ndStage.loc[(X_train_2ndStage['Arr'] == 0) & (X_train_2ndStage['AF'] == 1), 'label'] = 0\n",
    "        X_train_2ndStage.loc[(X_train_2ndStage['Arr'] == 1) & (X_train_2ndStage['AF'] == 0), 'label'] = 1\n",
    "        X_train_2ndStage = X_train_2ndStage.drop(columns=['AF', 'Arr', 'Disease'])\n",
    "        X_test_2ndStage = test_df.copy()\n",
    "        X_test_2ndStage = X_test_2ndStage[X_test_2ndStage['Disease']==1]\n",
    "        X_test_2ndStage['label'] = 0\n",
    "        X_test_2ndStage.loc[(X_test_2ndStage['Arr'] == 0) & (X_test_2ndStage['AF'] == 1), 'label'] = 0\n",
    "        X_test_2ndStage.loc[(X_test_2ndStage['Arr'] == 1) & (X_test_2ndStage['AF'] == 0), 'label'] = 1\n",
    "        self.traindf = X_train_2ndStage\n",
    "        self.testdf = X_test_2ndStage\n",
    "        return self.traindf, self.testdf\n",
    "    \n",
    "    # remving outliers using Isolation Forest\n",
    "    def OutlierRemoval(self):\n",
    "        train_df, X_test_df = self.prcoessing()\n",
    "        data = train_df.to_numpy()\n",
    "        X , y = data[:, :-1], data[:, -1]\n",
    "\n",
    "        iso = IsolationForest(contamination=0.1)\n",
    "        yhat = iso.fit_predict(X)\n",
    "        # select all rows that are not outliers\n",
    "        mask = yhat != -1\n",
    "        afterX, aftery = X[mask, :], y[mask]\n",
    "        unhealthy_df_no_outliers = pd.DataFrame(afterX,  columns = train_df.drop(columns=['label']).columns)\n",
    "        unhealthy_df_no_outliers['label'] = aftery\n",
    "        unhealthy_df_no_outliers['AF'] = 0\n",
    "        unhealthy_df_no_outliers['Arr'] = 0\n",
    "        unhealthy_df_no_outliers.loc[(unhealthy_df_no_outliers['label'] == 0), 'AF'] = 1\n",
    "        unhealthy_df_no_outliers.loc[(unhealthy_df_no_outliers['label'] == 1), 'Arr'] = 1\n",
    "        self.traindf = unhealthy_df_no_outliers\n",
    "        return self.traindf, self.testdf \n",
    "\n",
    "    def DataAugmentation(self):\n",
    "        train_df, X_test_df = self.OutlierRemoval()\n",
    "        arr_x = train_df.loc[:,train_df.columns != 'Arr']\n",
    "        arr_y = train_df['Arr']\n",
    "        AF_data = train_df.drop(columns=['Arr'], axis=1) # data with only the AF label\n",
    "        Arr_data = train_df.drop(columns=['AF'], axis=1) # data with only the Arr label\n",
    "        arr_smote_x = Arr_data.loc[:,Arr_data.columns != 'Arr']\n",
    "        arr_smote_y = Arr_data['Arr']\n",
    "\n",
    "        oversample_arr = SMOTE(sampling_strategy='auto')\n",
    "        arr_smote_x, arr_smote_y = oversample_arr.fit_resample(arr_smote_x, arr_smote_y)\n",
    "        af_smote_x = AF_data.loc[:,AF_data.columns != 'AF']\n",
    "        af_smote_y = AF_data['AF']\n",
    "\n",
    "        oversample_af = SMOTE(sampling_strategy='auto')\n",
    "        af_smote_x, af_smote_y = oversample_af.fit_resample(af_smote_x, af_smote_y)\n",
    "        arr_smote_x['Arr'] = arr_smote_y\n",
    "        af_smote_x['AF'] = af_smote_y\n",
    "        AF_only = af_smote_x[af_smote_x['AF'] == 1] # data with only positive labels of AF\n",
    "        Arr_only = arr_smote_x[arr_smote_x['Arr'] ==1] # data with only positive labels of Arr\n",
    "        with_smote_df = pd.concat([Arr_only,AF_only])\n",
    "        \n",
    "        with_smote_df.loc[(with_smote_df['Arr'] == 1) & (with_smote_df['AF'] == 0), 'label'] = 1\n",
    "        with_smote_df.loc[(with_smote_df['Arr'] == 0) & (with_smote_df['AF'] == 1), 'label'] = 0\n",
    "        self.df = with_smote_df\n",
    "        return self.df, X_test_df\n",
    "\n",
    "       \n",
    "    def finalCleanedDf(self):\n",
    "        new_df, X_test_df = self.DataAugmentation()\n",
    "        \n",
    "        new_df.loc[(new_df['label'] == 0), 'AF'] = 1\n",
    "        new_df.loc[(new_df['label'] == 0), 'Arr'] = 0\n",
    "        new_df.loc[(new_df['label'] == 1), 'Arr'] = 1\n",
    "        new_df.loc[(new_df['label'] == 1), 'AF'] = 0\n",
    "        self.df = new_df\n",
    "        return self.df, X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = SecondStageProcessing(train_df, test_df)\n",
    "train2_df, test2_df= instance.finalCleanedDf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = train2_df.drop(columns=['eid', 'AF', 'Arr', 'label'])\n",
    "y2_train = train2_df['label']\n",
    "\n",
    "X_test = test2_df.drop(columns=['eid', 'AF', 'Arr', 'Disease', 'label'])\n",
    "y_test = test2_df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimators = []\n",
    "\n",
    "model1 = xgb.XGBClassifier(objective='binary:logistic', subsample=0.75,  \n",
    "                          n_estimators=100, colsample_bytree = 0.99, learning_rate = 1,\n",
    "                max_depth = 10,  gamma=5, alpha = 1, seed=123, use_label_encoder=False, eval_metric='error')\n",
    "\n",
    "estimators.append(('XGBoost', model1))\n",
    "estimators.append(('bayes', GaussianNB()))\n",
    "estimators.append(('GradientDescent' , SGDClassifier(loss=\"modified_huber\", penalty=\"elasticnet\", max_iter=500)))\n",
    "ensemble = VotingClassifier(estimators, voting = 'soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.fit(X2_train, y2_train)\n",
    "y_pred_2 = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test, y_pred_2)\n",
    "print('f1_score: %.3f' % f1_score)\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred_2)\n",
    "print('Precision: %.3f' % precision)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, y_pred_2, average='binary')\n",
    "print('Recall: %.3f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(ensemble, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
